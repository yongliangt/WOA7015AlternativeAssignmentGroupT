{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Z_edArwA-X8"
      },
      "source": [
        "# Group T Alternative Assessment\n",
        "\n",
        "|Name|Matrix No|\n",
        "|:--------:|:----------:|\n",
        "|HOW MUN CHENG|23117642|\n",
        "|TUA YONG LIANG|23062790|\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtFRA75mYOf5",
        "outputId": "8b7571ab-cc57-4a94-f03b-19de07164dcb"
      },
      "outputs": [],
      "source": [
        "# connect Google Drive for importing input data\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKpJrmFhWL0R"
      },
      "outputs": [],
      "source": [
        "# import library, package\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib as mat\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "pd.options.display.max_colwidth = 100\n",
        "\n",
        "import random\n",
        "import os\n",
        "\n",
        "from numpy.random import seed\n",
        "seed(42)\n",
        "\n",
        "random.seed(42)\n",
        "os.environ['PYTHONHASHSEED'] = str(42)\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import callbacks\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import glob\n",
        "import cv2\n",
        "\n",
        "from tensorflow.random import set_seed\n",
        "set_seed(42)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8pvg6eiCqxW"
      },
      "outputs": [],
      "source": [
        "# training parameters\n",
        "\n",
        "image_size = 224 # resize input images\n",
        "batch = 32 # set number of samples processed per batch\n",
        "seed = 42 # fix randomness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-XOMoDSWL0R"
      },
      "outputs": [],
      "source": [
        "# define dataset paths\n",
        "\n",
        "train_path = \"/content/drive/MyDrive/chest_xray/train/\"\n",
        "test_path = \"/content/drive/MyDrive/chest_xray/test/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNzYMjm5BITc"
      },
      "outputs": [],
      "source": [
        "# use glob to collect file paths for input images\n",
        "\n",
        "train_normal = glob.glob(train_path+\"/NORMAL/*.jpeg\")\n",
        "train_pneumonia = glob.glob(train_path+\"/PNEUMONIA/*.jpeg\")\n",
        "\n",
        "test_normal = glob.glob(test_path+\"/NORMAL/*.jpeg\")\n",
        "test_pneumonia = glob.glob(test_path+\"/PNEUMONIA/*.jpeg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Da8ipiJsq0wp",
        "outputId": "1493d27f-9dea-406a-9963-acac4d3d49d3"
      },
      "outputs": [],
      "source": [
        "# create labeled dataframes for train data\n",
        "\n",
        "train_list = [x for x in train_normal]\n",
        "train_list.extend([x for x in train_pneumonia])\n",
        "\n",
        "df_train = pd.DataFrame(np.concatenate([['Normal']*len(train_normal) , ['Pneumonia']*len(train_pneumonia)]), columns = ['Class'])\n",
        "df_train['Image Path'] = [x for x in train_list]\n",
        "\n",
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "uGFkAzv_q52G",
        "outputId": "19d7cbef-8a44-4334-af41-c4d6fee59203"
      },
      "outputs": [],
      "source": [
        "# create labeled dataframes for test data\n",
        "\n",
        "test_list = [x for x in test_normal]\n",
        "test_list.extend([x for x in test_pneumonia])\n",
        "\n",
        "df_test = pd.DataFrame(np.concatenate([['Normal']*len(test_normal) , ['Pneumonia']*len(test_pneumonia)]), columns = ['Class'])\n",
        "df_test['Image Path'] = [x for x in test_list]\n",
        "\n",
        "df_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "vqt34Mtnq-Et",
        "outputId": "1975df82-3166-4cde-df6f-0ae3fb9323f6"
      },
      "outputs": [],
      "source": [
        "# plot for class distribution in train dataset\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "ax = sns.countplot(x='Class', data=df_train, palette=\"bright\")\n",
        "\n",
        "plt.xlabel(\"Class\", fontsize= 12)\n",
        "plt.ylabel(\"Number of Train Images\", fontsize= 12)\n",
        "plt.ylim(0,5200)\n",
        "plt.xticks([0,1], ['Normal', 'Pneumonia'], fontsize = 12)\n",
        "\n",
        "for p in ax.patches:\n",
        "    ax.annotate((p.get_height()), (p.get_x()+0.25, p.get_height()+200), fontsize = 14)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "ksnLi8OxrBLB",
        "outputId": "26b215bd-a2cf-4a40-fb65-81234d0c9d14"
      },
      "outputs": [],
      "source": [
        "# piechart for class distribution in train dataset\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "\n",
        "df_train['Class'].value_counts().plot(kind='pie',labels = ['',''], autopct='%1.1f%%', colors = ['green','blue'], explode = [0,0.03], textprops = {\"fontsize\":14})\n",
        "\n",
        "plt.legend(labels=['Pneumonia', 'Normal'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "2q4cemROrDhK",
        "outputId": "3305daf1-8c65-48da-af80-cee19dfb4f59"
      },
      "outputs": [],
      "source": [
        "# plot for class distribution in test dataset\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "\n",
        "ax = sns.countplot(x='Class', data=df_test, palette=\"bright\")\n",
        "\n",
        "plt.xlabel(\"Class\", fontsize= 12)\n",
        "plt.ylabel(\"Number of Test Images\", fontsize= 12)\n",
        "plt.ylim(0,500)\n",
        "plt.xticks([0,1], ['Normal', 'Pneumonia'], fontsize = 12)\n",
        "\n",
        "for p in ax.patches:\n",
        "    ax.annotate((p.get_height()), (p.get_x()+0.32, p.get_height()+25), fontsize = 14)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "3RRogeMfrGbH",
        "outputId": "f841d746-4dde-485b-a04e-a14fa82dfdf6"
      },
      "outputs": [],
      "source": [
        "#  piechart for class distribution in test dataset\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "\n",
        "df_test['Class'].value_counts().plot(kind='pie',labels = ['',''], autopct='%1.1f%%', colors = ['green','blue'], explode = [0,0.03], textprops = {\"fontsize\":13})\n",
        "\n",
        "plt.legend(labels=['Pneumonia', 'Normal'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "collapsed": true,
        "id": "lM9KPiRArJJd",
        "outputId": "eb9930ea-face-4e5a-8f27-c1ed59d8982a"
      },
      "outputs": [],
      "source": [
        "# display 6 normal images from train dataset\n",
        "\n",
        "print('Train Dataset: Normal')\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "for i in range(0, 6):\n",
        "    plt.subplot(2,3,i + 1)\n",
        "    image = cv2.imread(train_normal[i])\n",
        "    image = cv2.resize(image, (image_size,image_size))\n",
        "    plt.imshow(image)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "collapsed": true,
        "id": "RNdI8zvdrPUq",
        "outputId": "1536db01-4d33-4355-8e1f-e1fa60da4d1d"
      },
      "outputs": [],
      "source": [
        "# display 6 Pneumonia images from train dataset\n",
        "\n",
        "print('Train Dataset: Pneumonia')\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "for i in range(0, 6):\n",
        "    plt.subplot(2,3,i + 1)\n",
        "    image = cv2.imread(train_pneumonia[i])\n",
        "    image = cv2.resize(image, (image_size,image_size))\n",
        "    plt.imshow(image)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "collapsed": true,
        "id": "OPX00_sBrR9i",
        "outputId": "4d5854d7-fcc2-472c-dc93-18a3dfab2186"
      },
      "outputs": [],
      "source": [
        "# display 6 normal images from test dataset\n",
        "\n",
        "print('Test Dataset: Normal')\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "for i in range(0, 6):\n",
        "    plt.subplot(2,3,i + 1)\n",
        "    image = cv2.imread(test_normal[i])\n",
        "    image = cv2.resize(image, (image_size,image_size))\n",
        "    plt.imshow(image)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "collapsed": true,
        "id": "mAPZwF88rUPI",
        "outputId": "0006794b-e19b-49a4-d4c8-c7f294a28f3f"
      },
      "outputs": [],
      "source": [
        "# display 6 Pneumonia images from test dataset\n",
        "\n",
        "print('Test Dataset: Pneumonia')\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "for i in range(0, 6):\n",
        "    plt.subplot(2,3,i + 1)\n",
        "    image = cv2.imread(test_pneumonia[i])\n",
        "    image = cv2.resize(image, (image_size,image_size))\n",
        "    plt.imshow(image)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nn65K-pkrme8"
      },
      "outputs": [],
      "source": [
        "# stratified split 80% train, 20% validation on the train dataset\n",
        "\n",
        "train_df, val_df = train_test_split(df_train, test_size = 0.20, random_state = seed, stratify = df_train['Class'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "2cqL6EOir949",
        "outputId": "ee4fd476-583e-43bc-9c53-e2ab31d9f6c4"
      },
      "outputs": [],
      "source": [
        "# display train dataframe after split\n",
        "\n",
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "yJZ5ZdwEsA3f",
        "outputId": "f6b0856e-e2e4-4069-867a-0d3ac216c9eb"
      },
      "outputs": [],
      "source": [
        "# display validation dataframe after split\n",
        "\n",
        "val_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSrLZYcwsCp0",
        "outputId": "e543f26e-94b2-460d-9ec0-342354237c36"
      },
      "outputs": [],
      "source": [
        "# data preprocessing\n",
        "\n",
        "train_data_generator = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "val_data_generator = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "test_data_generator = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "train_generator = train_data_generator.flow_from_dataframe(\n",
        "                                             dataframe = train_df,\n",
        "                                             x_col = 'Image Path',\n",
        "                                             y_col = 'Class',\n",
        "                                             target_size = (image_size, image_size),\n",
        "                                             class_mode = 'binary',\n",
        "                                             batch_size = batch,\n",
        "                                             seed = seed)\n",
        "\n",
        "val_generator = val_data_generator.flow_from_dataframe(\n",
        "                                         dataframe = val_df,\n",
        "                                         x_col = 'Image Path',\n",
        "                                         y_col = 'Class',\n",
        "                                         target_size = (image_size, image_size),\n",
        "                                         class_mode = 'binary',\n",
        "                                         batch_size = batch,\n",
        "                                         seed = seed)\n",
        "\n",
        "test_generator = test_data_generator.flow_from_dataframe(\n",
        "                                          dataframe = df_test,\n",
        "                                          x_col = 'Image Path',\n",
        "                                          y_col = 'Class',\n",
        "                                          target_size = (image_size, image_size),\n",
        "                                          class_mode = 'binary',\n",
        "                                          batch_size = 1,\n",
        "                                          shuffle = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXlpJbimsRTk"
      },
      "outputs": [],
      "source": [
        "# cnn model with dropout and batch normalization\n",
        "\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "def create_model():\n",
        "\n",
        "    # input shape: [width, height, color channels]\n",
        "    inputs = layers.Input(shape=(image_size, image_size, 3))\n",
        "\n",
        "    # 1st block\n",
        "    x = layers.Conv2D(filters=16, kernel_size=3, padding='valid',\n",
        "                      kernel_regularizer=regularizers.l2(0.1))(inputs)  # L2 Regularization\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.MaxPool2D()(x)\n",
        "    x = layers.Dropout(0.3)(x) # dropout layer\n",
        "\n",
        "    # 2nd block\n",
        "    x = layers.Conv2D(filters=32, kernel_size=3, padding='valid',\n",
        "                      kernel_regularizer=regularizers.l2(0.1))(x)  # L2 Regularization\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.MaxPool2D()(x)\n",
        "    x = layers.Dropout(0.3)(x) # dropout layer\n",
        "\n",
        "    # 3rd block\n",
        "    x = layers.Conv2D(filters=64, kernel_size=3, padding='valid',\n",
        "                      kernel_regularizer=regularizers.l2(0.1))(x)  # L2 Regularization\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.MaxPool2D()(x)\n",
        "    x = layers.Dropout(0.4)(x) # dropout layer\n",
        "\n",
        "    # fully connected head\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(32, activation='relu')(x)\n",
        "    x = layers.Dropout(0.5)(x) # dropout layer\n",
        "\n",
        "    # final output layer\n",
        "    output = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = keras.Model(inputs=[inputs], outputs=output)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4mM8Kj7sKR1"
      },
      "outputs": [],
      "source": [
        "# callbacks for early stopping and reduce learning rate on plateau\n",
        "\n",
        "early_stopping = callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    min_delta=1e-7,\n",
        "    restore_best_weights=True,\n",
        ")\n",
        "\n",
        "plateau = callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor = 0.2,\n",
        "    patience = 10,\n",
        "    min_delta = 1e-7,\n",
        "    cooldown = 0,\n",
        "    verbose = 1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "id": "VP9lXzDD3ZKW",
        "outputId": "934f797a-0272-472f-8e52-75fabcfd8f53"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# clear session to avoid model stacking issues\n",
        "keras.backend.clear_session()\n",
        "\n",
        "# create model\n",
        "model = create_model()\n",
        "\n",
        "# compile model\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=5e-4, clipvalue=1.0), # apply gradient clipping to the optimizer\n",
        "    metrics=['binary_accuracy']\n",
        ")\n",
        "\n",
        "# print model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZPF1hG_kuQ-"
      },
      "outputs": [],
      "source": [
        "# use class weight to handle data imbalance\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_subset['Class']),\n",
        "    y=train_df['Class']\n",
        ")\n",
        "class_weights = dict(enumerate(class_weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VfwTF1ExNVoZ",
        "outputId": "4a82311b-e32c-46ce-d4f3-986327fa76fc"
      },
      "outputs": [],
      "source": [
        "# train base CNN model\n",
        "\n",
        "# check lengths of DataFrames\n",
        "print(len(train_df), len(val_df))\n",
        "\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "# reduce learning rate when validation loss plateaus\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',  # watch validation loss\n",
        "    factor=0.5,          # reduce learning rate by a factor of 0.5\n",
        "    patience=5,          # wait 5 epochs before reducing the learning rate\n",
        "    min_lr=1e-6          # minimum learning rate\n",
        ")\n",
        "\n",
        "# calculate steps\n",
        "steps_per_epoch = int(len(train_df) / batch)\n",
        "validation_steps = int(len(val_df) / batch)\n",
        "\n",
        "# train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=50,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[early_stopping, plateau], #\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_steps=validation_steps,\n",
        "    class_weight=class_weights #\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_wzBeNpsxmW"
      },
      "outputs": [],
      "source": [
        "# base CNN model\n",
        "# plot learning curves- accuracy\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(20,10))\n",
        "sns.lineplot(x = history.epoch, y = history.history['binary_accuracy'])\n",
        "sns.lineplot(x = history.epoch, y = history.history['val_binary_accuracy'])\n",
        "ax.set_title('Learning Curve (Accuracy)')\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylim(0.6, 1.0)\n",
        "ax.legend(['Train', 'Validation'], loc='best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcWNii1bRh8c"
      },
      "outputs": [],
      "source": [
        "# base CNN model\n",
        "# plot learning curves- loss\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(20,8))\n",
        "sns.lineplot(x = history.epoch, y = history.history['loss'])\n",
        "sns.lineplot(x = history.epoch, y = history.history['val_loss'])\n",
        "ax.set_title('Learning Curve (Loss)')\n",
        "ax.set_ylabel('Loss')\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylim(0, 7)\n",
        "ax.legend(['train', 'val'], loc='best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jw4CWpyGs47w"
      },
      "outputs": [],
      "source": [
        "# evaluate model's performance on validation dataset\n",
        "\n",
        "score_val = model.evaluate(val_generator, steps=int(len(val_df) / batch), verbose=0)\n",
        "print(f'Validation loss: {score_val[0]:.4f}')\n",
        "print(f'Validation accuracy: {score_val[1]:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVAk7uySs5Ig"
      },
      "outputs": [],
      "source": [
        "# base CNN model\n",
        "# evaluate model's performance on test dataset\n",
        "\n",
        "score_test = model.evaluate(test_generator, steps=len(df_test), verbose=0)\n",
        "print(f'Test loss: {score_test[0]:.4f}')\n",
        "print(f'Test accuracy: {score_test[1]:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKah-pcWa493"
      },
      "outputs": [],
      "source": [
        "# base CNN model\n",
        "# labels\n",
        "\n",
        "number_label = {'Normal': 0, 'Pneumonia' : 1}\n",
        "Y_test = df_test['Class'].copy().map(number_label).astype('int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LT_ukHja79p"
      },
      "outputs": [],
      "source": [
        "# base CNN model\n",
        "# evaluate the trained base model\n",
        "\n",
        "test_generator.reset()\n",
        "predictions = model.predict(test_generator, steps=len(test_generator), verbose=0)\n",
        "pred_labels= np.where(predictions>0.5, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pg-ghkRbGso"
      },
      "outputs": [],
      "source": [
        "# base CNN model\n",
        "# confusion matrix\n",
        "\n",
        "confusion_matrix = metrics.confusion_matrix(Y_test, pred_labels)\n",
        "sns.heatmap(confusion_matrix, annot=True, fmt=\"d\")\n",
        "\n",
        "plt.xlabel(\"Predicted Label\", fontsize= 12)\n",
        "plt.ylabel(\"True Label\", fontsize= 12)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWkZrjeebGu-"
      },
      "outputs": [],
      "source": [
        "# base CNN model\n",
        "# classification report\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "print(metrics.classification_report(Y_test, pred_labels, labels=[0, 1], digits=4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-U1IRj5bMRZ"
      },
      "outputs": [],
      "source": [
        "# base CNN model\n",
        "# ROC-AUC\n",
        "\n",
        "ROC_AUC = metrics.roc_auc_score(Y_test, predictions)\n",
        "print('ROC_AUC: ', ROC_AUC)\n",
        "\n",
        "fpr, tpr, thresholds = metrics.roc_curve(Y_test, predictions)\n",
        "\n",
        "plt.plot(fpr, tpr, label = 'ROC_AUC = %0.4f' % ROC_AUC)\n",
        "\n",
        "plt.xlabel(\"False Positive Rate\", fontsize= 12)\n",
        "plt.ylabel(\"True Positive Rate\", fontsize= 12)\n",
        "plt.legend(loc=\"lower right\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vSk4TUgs8bv"
      },
      "outputs": [],
      "source": [
        "# transfer learning\n",
        "# ResNet152V2 model pre-trained on ImageNet\n",
        "\n",
        "base_model = tf.keras.applications.ResNet152V2(\n",
        "    weights='imagenet', # use ImageNet pre-trained weights\n",
        "    input_shape=(image_size, image_size, 3), # define the input shape (height, width, channels)\n",
        "    include_top=False) # exclude the top fully connected layers\n",
        "\n",
        "base_model.trainable = False # freeze the base model to prevent updating the weights during training\n",
        "\n",
        "# define model architecture\n",
        "def get_pretrained():\n",
        "\n",
        "    inputs = layers.Input(shape=(image_size, image_size, 3))\n",
        "\n",
        "# pass input through the pre-trained ResNet152V2 model to extract features\n",
        "    x = base_model(inputs)\n",
        "\n",
        "    # add custom head on top of feature extractor\n",
        "    x = layers.GlobalAveragePooling2D()(x) # apply global average pooling to reduce the spatial dimensions of the output\n",
        "    x = layers.Dense(128, activation='relu')(x) # add a dense layer with 128 units and ReLU activation to learn new representations\n",
        "    x = layers.Dropout(0.1)(x) # introduce dropout for regularization to help prevent overfitting\n",
        "\n",
        "    # dense layer with a sigmoid activation for binary classification (0 or 1)\n",
        "    output = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    # build the model by specifying input and output layers\n",
        "    model = keras.Model(inputs=[inputs], outputs=output)\n",
        "\n",
        "    return model # return the constructed model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkEXcGAAgnXR"
      },
      "outputs": [],
      "source": [
        "# initialize the pretrained model, compile it with Adam optimizer\n",
        "\n",
        "keras.backend.clear_session()\n",
        "\n",
        "model_pretrained = get_pretrained()\n",
        "model_pretrained.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=5e-4, clipvalue=1.0),\n",
        "    metrics=['binary_accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "model_pretrained.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrbsTUgHtJNt"
      },
      "outputs": [],
      "source": [
        "# train the pretrained model\n",
        "\n",
        "history = model_pretrained.fit(\n",
        "    train_generator,\n",
        "    epochs=50,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[early_stopping, plateau],\n",
        "    steps_per_epoch=len(train_subset) // batch,   # use integer division for steps_per_epoch\n",
        "    validation_steps=len(val_df) // batch    # same for validation_steps\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5owP8FIbtMVb"
      },
      "outputs": [],
      "source": [
        "# the pretrained model\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(20,10))\n",
        "sns.lineplot(x = history.epoch, y = history.history['loss'])\n",
        "sns.lineplot(x = history.epoch, y = history.history['val_loss'])\n",
        "ax.set_title('Learning Curve (Loss)')\n",
        "ax.set_ylabel('Loss')\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylim(0, 0.5)\n",
        "ax.legend(['Train', 'Validation'], loc='best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjeRzbCCtJt_"
      },
      "outputs": [],
      "source": [
        "# the pretrained model\n",
        "# plot of learning curve (accuracy)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(20,10))\n",
        "sns.lineplot(x = history.epoch, y = history.history['binary_accuracy'])\n",
        "sns.lineplot(x = history.epoch, y = history.history['val_binary_accuracy'])\n",
        "ax.set_title('Learning Curve (Accuracy)')\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylim(0.80, 1.0)\n",
        "ax.legend(['Train', 'Validation'], loc='best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfgjnTz6tXpo"
      },
      "outputs": [],
      "source": [
        "# the pretrained model\n",
        "# validation score\n",
        "\n",
        "score_val = model.evaluate(val_generator, steps=int(len(val_df) / batch), verbose=0)\n",
        "print(f'Validation loss: {score_val[0]:.4f}')\n",
        "print(f'Validation accuracy: {score_val[1]:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HUItmU1tY-Y"
      },
      "outputs": [],
      "source": [
        "# the pretrained model\n",
        "# test score\n",
        "\n",
        "score_test = model.evaluate(test_generator, steps=len(df_test), verbose=0)\n",
        "print(f'Test loss: {score_test[0]:.4f}')\n",
        "print(f'Test accuracy: {score_test[1]:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TbFrBJTtbwQ"
      },
      "outputs": [],
      "source": [
        "# the pretrained model\n",
        "# fine tuning\n",
        "base_model.trainable = True\n",
        "\n",
        "# freeze layers\n",
        "for layer in base_model.layers[:-13]:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyhyNX1ttdYu"
      },
      "outputs": [],
      "source": [
        "# the pretrained model\n",
        "# check which layers are tuneable (trainable)\n",
        "\n",
        "for layer_number, layer in enumerate(base_model.layers):\n",
        "    print(layer_number, layer.name, layer.trainable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKP6pk06tfvK"
      },
      "outputs": [],
      "source": [
        "# the pretrained model\n",
        "# compile the pretrained model with Adam optimizer\n",
        "\n",
        "model_pretrained.compile(loss='binary_crossentropy'\n",
        "              , optimizer = keras.optimizers.Adam(learning_rate=5e-4), metrics='binary_accuracy')\n",
        "\n",
        "model_pretrained.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnorpAEZtky4"
      },
      "outputs": [],
      "source": [
        "# the pretrained model\n",
        "# train the pretrained model\n",
        "\n",
        "history = model_pretrained.fit(train_generator,\n",
        "          batch_size = batch, epochs = 50,\n",
        "          validation_data=val_generator,\n",
        "          callbacks=[early_stopping, plateau],\n",
        "          steps_per_epoch=(len(train_df)/batch),\n",
        "          validation_steps=(len(val_df)/batch));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9nuOkBwtmh5"
      },
      "outputs": [],
      "source": [
        "# the pretrained model\n",
        "# plot learning curve (loss)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(20,8))\n",
        "sns.lineplot(x = history.epoch, y = history.history['loss'])\n",
        "sns.lineplot(x = history.epoch, y = history.history['validation_loss'])\n",
        "ax.set_title('Learning Curve (Loss)')\n",
        "ax.set_ylabel('Loss')\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylim(0, 0.3)\n",
        "ax.legend(['Train', 'Validation'], loc='best')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpS8W04Htsy-"
      },
      "outputs": [],
      "source": [
        "# the pretrained model\n",
        "# plot learning curve (accuracy)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(20,8))\n",
        "sns.lineplot(x = history.epoch, y = history.history['binary_accuracy'])\n",
        "sns.lineplot(x = history.epoch, y = history.history['validation_binary_accuracy'])\n",
        "ax.set_title('Learning Curve (Accuracy)')\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylim(0.90, 1.0)\n",
        "ax.legend(['Train', 'Validation'], loc='best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moMXVFNhtvvW"
      },
      "outputs": [],
      "source": [
        "# the pretrained model\n",
        "# validation score\n",
        "\n",
        "score = model_pretrained.evaluate(val_generator, steps = len(val_df)/batch, verbose = 0)\n",
        "print('Validation loss:', score[0])\n",
        "print('Validation accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ivcTtnetwjJ"
      },
      "outputs": [],
      "source": [
        "# the pretrained model\n",
        "# test score\n",
        "\n",
        "score = model_pretrained.evaluate(test_generator, steps = len(df_test), verbose = 0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "A-SrRPnJtzsV",
        "outputId": "cff3fdf4-1db2-4495-df19-854141480a9f"
      },
      "outputs": [],
      "source": [
        "# the pretrained model\n",
        "# labels\n",
        "\n",
        "number_label = {'Normal': 0, 'Pneumonia' : 1}\n",
        "Y_test = df_test['class'].copy().map(number_label).astype('int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XA1CwFQJt06Z"
      },
      "outputs": [],
      "source": [
        "# the pretrained model\n",
        "# evaluate the trained pretrained model\n",
        "\n",
        "test_generator.reset()\n",
        "predictions = model_pretrained.predict(test_generator, steps=len(test_generator), verbose=0)\n",
        "pred_labels= np.where(predictions>0.5, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJFzgIj-t2gb"
      },
      "outputs": [],
      "source": [
        "# the pretrained model\n",
        "# test accuracy\n",
        "\n",
        "print(\"Test Accuracy: \", accuracy_score(Y_test, pred_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WQKeBNut4zS"
      },
      "outputs": [],
      "source": [
        "# the pretrained model\n",
        "# confusion matrix\n",
        "\n",
        "confusion_matrix = metrics.confusion_matrix(Y_test, pred_labels)\n",
        "sns.heatmap(confusion_matrix, annot=True, fmt=\"d\")\n",
        "\n",
        "plt.xlabel(\"Predicted Label\", fontsize= 12)\n",
        "plt.ylabel(\"True Label\", fontsize= 12)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGLGO_13t63f"
      },
      "outputs": [],
      "source": [
        "# the pretrained model\n",
        "# classification report\n",
        "print(metrics.classification_report(Y_test, pred_labels, labels = [0, 1],digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6E6kr3ht8xP"
      },
      "outputs": [],
      "source": [
        "# transfer learning\n",
        "# the pretrained model\n",
        "ROC_AUC = metrics.roc_auc_score(Y_test, predictions)\n",
        "print('ROC_AUC: ', ROC_AUC)\n",
        "\n",
        "fpr, tpr, thresholds = metrics.roc_curve(Y_test, predictions)\n",
        "\n",
        "plt.plot(fpr, tpr, label = 'ROC_AUC = %0.3f' % ROC_AUC)\n",
        "\n",
        "plt.xlabel(\"False Positive Rate\", fontsize= 12)\n",
        "plt.ylabel(\"True Positive Rate\", fontsize= 12)\n",
        "plt.legend(loc=\"lower right\")\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
